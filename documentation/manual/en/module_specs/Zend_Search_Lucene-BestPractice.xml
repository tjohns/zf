<sect1 id="zend.search.lucene.best-practice">
    <title>Best practice</title>

    <sect2 id="zend.search.lucene.best-practice.field-names">
        <title>Field names</title>

        <para>
            There are no limitations for field names in Zend_Search_Lucene.
        </para>

        <para>
            Nevertheless it's good idea not to use '<emphasis>id</emphasis>' and '<emphasis>score</emphasis>' names
            to avoid ambiguity in <code>QueryHit</code> properties names.
        </para>

        <para>
            <code>Zend_Search_Lucene_Search_QueryHit</code> <code>id</code> and <code>score</code> properties always refer
            to internal Lucene document id and hit <link linkend="zend.search.lucene.searching.results-scoring">score</link>.
            If indexed document has the same stored fields, you have to use <code>getDocument()</code> method to access them:

            <programlisting role="php"><![CDATA[<?php
$hits = $index->find($query);

foreach ($hits as $hit) {
    // Get 'title' document field
    $title = $hit->title;

    // Get 'contents' document field
    $contents = $hit->contents;


    // Get internal Lucene document id
    $id = $hit->id;

    // Get query hit score
    $score = $hit->score;


    // Get 'id' document field
    $docId = $hit->getDocument()->id;

    // Get 'score' document field
    $docId = $hit->getDocument()->score;

    // Another way to get 'title' document field
    $title = $hit->getDocument()->title;
}
]]></programlisting>
        </para>
    </sect2>


    <sect2 id="zend.search.lucene.best-practice.indexing-performance">
        <title>Indexing performance</title>

        <para>
            Indexing performance is a compromise between used resources, indexing time and index quality.
        </para>

        <para>
            Index quality is completely determined by number of index segments.
        </para>

        <para>
            Each index segment is entirely independent portion of data. So index containing more segments needs
            more memory and more time for searching.
        </para>

        <para>
            Index optimization is a process of merging several segments into new one. Fully optimized index contains
            only one segment.
        </para>

        <para>
            Full index optimization may be performed with 'optimize()' method:
            <programlisting role="php"><![CDATA[<?php
$index = Zend_Search_Lucene::open($indexPath);

$index->optimize();
]]></programlisting>
        </para>

        <para>
            Index optimization works with data streams and doesn't take a lot of memory, but takes processor resources and time.
        </para>

        <para>
            Lucene index segments are not updatable by their nature (update operation needs segment file
            to be completely rewritten). So adding new document(s) to the index always generates new segment.
            It decreases index quality.
        </para>

        <para>
            Index auto-optimization process is performed after each segment generation and consists in partial segments merging.
        </para>

        <para>
            There are three options to control behavior of auto-optimization
            (see <link linkend="zend.search.lucene.index-creation.optimization">Index optimization</link> section):
            <itemizedlist>
                <listitem>
                    <para><emphasis>MaxBufferedDocs</emphasis> is a number of documents buffered in memory before new segment is generated
                          and written to a hard drive.</para>
                </listitem>
                <listitem>
                    <para><emphasis>MaxMergeDocs</emphasis> is a maximum number of documents merged by auto-optimization process
                          into new segment.</para>
                </listitem>
                <listitem>
                    <para><emphasis>MergeFactor</emphasis> determines how often auto-optimization is performed.</para>
                </listitem>
            </itemizedlist>
            <note>
                <para>
                    All these options are Zend_Search_Lucene object properties, but not index properties. So they affect only current
                    <code>Zend_Search_Lucene</code> object behavior and may vary for different scripts.
                </para>
            </note>
        </para>

        <para>
            <emphasis>MaxBufferedDocs</emphasis> doesn't matter if you index only one document per script execution. To the contrary, it's very important
            for batch indexing. Greater value increases indexing performance, but also needs more memory.
        </para>

        <para>
            There are no way to calculate best value for <emphasis>MaxBufferedDocs</emphasis> parameter because it depends on documents size, used
            analyzer and allowed memory.
        </para>

        <para>
            Good way to get right value is to perform several tests with largest document you expect to be added to the index
            <footnote><para><code>memory_get_usage()</code> and <code>memory_get_peak_usage()</code> may be used to control
            memory usage.</para></footnote>. That's good idea not to use more than a half of allowed memory.
        </para>


        <para>
            <emphasis>MaxMergeDocs</emphasis> limits segment size (in terms of documents). So it limits auto-optimization time. That guarantees
            <code>addDocument()</code> method to be not executed more than a certain time. It's important for interactive application.
        </para>

        <para>
            Decreasing <emphasis>MaxMergeDocs</emphasis> parameter also may improve batch indexing performance. Index auto-optimization is iterative process
            and is performed step by step. Small segments are merged into larger, at some moment they are merged into even greater and
            so on. Full index optimization is much more effective.
        </para>

        <para>
            On the over hand, smaller segments decreases index quality and may generate too many segments. It may be a cause of
            the "Too many open files" error determined by OS limitations <footnote><para>Zend_Search_Lucene keeps each segment file opened
            to improve search performance.</para></footnote>.
        </para>

        <para>
            So background index optimization should be performed for interactive indexing mode and <emphasis>MaxMergeDocs</emphasis> shouldn't be
            too low for batch indexing.
        </para>


        <para>
            <emphasis>MergeFactor</emphasis> affects auto-optimization frequency. Less values increases quality of unoptimized index. Larger values increases
            indexing performance, but also increases number of segments. It again may be a cause of the "Too many open files" error.
        </para>

        <para>
            <emphasis>MergeFactor</emphasis> groups index segments by their size:
            <orderedlist>
                <listitem><para>Not greater than <emphasis>MaxBufferedDocs</emphasis>.</para></listitem>
                <listitem><para>Greater than <emphasis>MaxBufferedDocs</emphasis>, but not greater than
                                <emphasis>MaxBufferedDocs</emphasis>*<emphasis>MergeFactor</emphasis>.</para></listitem>
                <listitem><para>Greater than <emphasis>MaxBufferedDocs</emphasis>*<emphasis>MergeFactor</emphasis>, but not greater than
                <emphasis>MaxBufferedDocs</emphasis>*<emphasis>MergeFactor</emphasis>*<emphasis>MergeFactor</emphasis>.</para></listitem>
                <listitem><para>...</para></listitem>
            </orderedlist>
        </para>

        <para>
            Zend_Search_Lucene checks at each <code>addDocument()</code> call if merging of any segments group may move newly created segment
            into next group. If yes, then merging is performed.
        </para>

        <para>
            So index with N groups may contain <emphasis>MaxBufferedDocs</emphasis> + (N-1)*<emphasis>MergeFactor</emphasis> segments and contains at least
            <emphasis>MaxBufferedDocs</emphasis>*<emphasis>MergeFactor</emphasis><superscript>(N-1)</superscript> documents.
        </para>

        <para>
            It gives good approximation for number of segments in the index:
        </para>
        <para>
            <emphasis>NumberOfSegments</emphasis>  &lt;= <emphasis>MaxBufferedDocs</emphasis> + <emphasis>MergeFactor</emphasis>*log
            <subscript><emphasis>MergeFactor</emphasis></subscript> (<emphasis>NumberOfDocuments</emphasis>/<emphasis>MaxBufferedDocs</emphasis>)
        </para>

        <para>
            <emphasis>MaxBufferedDocs</emphasis> is determined by allowed memory. It gives the possibility to choose appropriate merge factor to get reasonable
            number of segments.
        </para>


        <para>
            Tuning <emphasis>MergeFactor</emphasis> parameter is more effective for batch indexing performance than <emphasis>MaxMergeDocs</emphasis>. But it's more rough.
            So use above estimation for tuning <emphasis>MergeFactor</emphasis>, then play with <emphasis>MaxMergeDocs</emphasis> to get best batch indexing performance.
        </para>
    </sect2>

    <sect2 id="zend.search.lucene.best-practice.shutting-down">
        <title>Index shutting down</title>

        <para>
            <code>Zend_Search_Lucene</code> object performs some work at shutting down time if any documents were added to the index.
        </para>

        <para>
            It's concerned with buffering added document before generating new segment.
        </para>

        <para>
            It also may cause auto-optimization process.
        </para>

        <para>
            Index object is automatically shut down when it, and all returned QueryHit objects, go out of scope.
        </para>

        <para>
            If index object is stored in global variable than it's destroyed only at the end of script execution<footnote><para>It also
            may occur if index or QueryHit objects are referred in some complex data structures. Ex. PHP destroys objects
            with cyclic references only at the end of script execution.</para></footnote>.
        </para>

        <para>
            PHP exception processing is also shut down at this moment.
        </para>

        <para>
            It doesn't prevent normal index shutdown process, but may prevent to get correct error diagnostic if any error occurs.
        </para>

        <para>
            There are two ways which may help to avoid this problem.
        </para>

        <para>
            The first is to force going out of scope:
            <programlisting role="php"><![CDATA[<?php
$index = Zend_Search_Lucene::open($indexPath);

...

unset($index);
?>]]></programlisting>
        </para>

        <para>
            And the second is to perform commit operation before the end of script execution:
            <programlisting role="php"><![CDATA[<?php
$index = Zend_Search_Lucene::open($indexPath);

$index->commit();
?>]]></programlisting>
            This possibility is also described in "<link linkend="zend.search.lucene.advanced.static">Advanced. Using index as static property</link>"
            documentation section.
        </para>
    </sect2>

    <sect2 id="zend.search.lucene.best-practice.unique-id">
        <title>Retrieving documents by unique id</title>

        <para>
            It's common practice to store some unique document id in the index. Ex. url, path, database id or some other.
        </para>

        <para>
            <code>Zend_Search_Lucene</code> provides <code>termDocs()</code> method for retrieving documents containing specified term.
        </para>

        <para>
            It's more effective than <code>find()</code> method:
            <programlisting role="php"><![CDATA[<?php
// Retrieving documents with find() method using query string
$query = $idFieldName . ':' . $docId;
$hits  = $index->find($query);
foreach ($hits as $hit) {
    $title    = $hit->title;
    $contents = $hit->contents;
    ...
}
...

// Retrieving documents with find() method using query API
$term = new Zend_Search_Lucene_Index_Term($docId, idFieldName);
$query = new Zend_Search_Lucene_Search_Query_Term($term);
$hits  = $index->find($query);
foreach ($hits as $hit) {
    $title    = $hit->title;
    $contents = $hit->contents;
    ...
}

...

// Retrieving documents with termDocs() method
$term = new Zend_Search_Lucene_Index_Term($docId, idFieldName);
$docIds  = $index->termDocs($term);
foreach ($docIds as $id) {
    $doc = $index->getDocument($id);
    $title    = $doc->title;
    $contents = $doc->contents;
    ...
}
]]></programlisting>
        </para>
    </sect2>

    <sect2 id="zend.search.lucene.best-practice.memory-usage">
        <title>Memory usage</title>

        <para>
            Zend_Search_Lucene is memory expensive module.
        </para>

        <para>
            It uses memory to cache some information and speed up search and indexing.
        </para>

        <para>
            The behavior differs for different modes.
        </para>

        <para>
            Terms dictionary index is loaded during the search. It's actually each 128<superscript>th</superscript>
            <footnote><para>Lucene file format allows you to change this number, but Zend_Search_Lucene doesn't give a possibility
            to do this through its API. Nevertheless you still have possibility to change this value if index is prepared with another
            Lucene implementation.</para></footnote> term of full dictionary.
        </para>

        <para>
            Thus memory usage is increased if you have high number of unique terms. This may happen if you use untokenized phrases as a field values
            or index a large volume of non-text information.
        </para>

        <para>
            Unoptimized index consists of several segments. It also increases memory usage. Segments are independent, so each segment contains
            his own terms dictionary and terms dictionary index. If index consists of <emphasis>N</emphasis> segments it may increase memory
            usage by <emphasis>N</emphasis> times in worst case. Perform index optimization to merge all segments into one.
        </para>

        <para>
            Indexing uses the same memory as searching plus memory for buffering documents. The amount of memory used for this may be managed with
            <emphasis>MaxBufferedDocs</emphasis> parameter.
        </para>

        <para>
            Index optimization (full or partial) uses stream like data processing and doesn't take a lot of memory.
        </para>
    </sect2>

    <sect2 id="zend.search.lucene.best-practice.encoding">
        <title>Encoding</title>

        <para>
            Zend_Search_Lucene works with UTF-8 strings internally. So all strings returned by Zend_Search_Lucene are UTF-8 encoded.
        </para>

        <para>
            You shouldn't care about encoding if you works with pure ASCII data, but should be careful in other cases.
        </para>

        <para>
            Wrong encoding may cause error notices at the encoding convertion time or cause loss of data.
        </para>

        <para>
            Zend_Search_Lucene gives wide range of the possibilities to specify actual encoding of indexed documents and parsed queries.
        </para>

        <para>
            Encoding may be explicitly specified as an optional parameter of field creation methods:
            <programlisting role="php"><![CDATA[<?php
$doc = new Zend_Search_Lucene_Document();
$doc->addField(Zend_Search_Lucene_Field::Text('title', $title, 'iso-8859-1'));
$doc->addField(Zend_Search_Lucene_Field::UnStored('contents', $contents, 'utf-8'));
]]></programlisting>
            That's the best way to avoid ambiguity in encoding specification.
        </para>

        <para>
            If optional encoding parameter is omitted, then current locale is used. Current locale may also contain character set specification
            in addition to the language information:
            <programlisting role="php"><![CDATA[<?php
setlocale(LC_ALL, 'fr_FR');
...

setlocale(LC_ALL, 'de_DE.iso-8859-1');
...

setlocale(LC_ALL, 'ru_RU.UTF-8');
...
]]></programlisting>
        </para>

        <para>
            The same approach is used to specify query string encoding.
        </para>

        <para>
            If encoding is not specified in any special way, then current locale is used.
        </para>

        <para>
            Encoding may be pointed as an optional parameter, if query is parsed explicitly before search:
            <programlisting role="php"><![CDATA[<?php
$query = Zend_Search_Lucene_Search_QueryParser::parse($queryStr, 'iso-8859-5');
$hits = $index->find($query);
...
]]></programlisting>
        </para>

        <para>
            The default encoding may also be specified with <code>setDefaultEncoding()</code> method:
            <programlisting role="php"><![CDATA[<?php
Zend_Search_Lucene_Search_QueryParser::setDefaultEncoding('iso-8859-1');
$hits = $index->find($queryStr);
...
]]></programlisting>
            Empty string means 'current locale'.
        </para>

        <para>
            Since correct encoding is specified it can be correctly processed by analyzer. The actual behavior depends on analyzer been used.
            See <link linkend="zend.search.lucene.charset">Character set</link> documentation section for details.
        </para>
    </sect2>

    <sect2 id="zend.search.lucene.best-practice.maintenance">
        <title>Index maintenance</title>

        <para>
            It should be clear, that Zend_Search_Lucene as well as any other Lucene implementation is not a "database".
        </para>

        <para>
            It should not be used as some kind of data storage. It doesn't provide partial backup/restoring functionality, journaling, logging, transactions
            and many other things provided by database management systems.
        </para>

        <para>
            Nevertheless, Zend_Search_Lucene tries to keep index in a consistent state at any time.
        </para>

        <para>
            Index backup/restoring should be performed off-line by complete copying of index folder.
        </para>

        <para>
            If index corruption happens because of any reason, then index should be completely restored or re-builded.
        </para>

        <para>
            So that's good idea to backup large indexes and store changelog somewhere to perform manual restore + rollforward operation
            if it's necessary. It essentially reduces index restoring time.
        </para>

    </sect2>
</sect1>
